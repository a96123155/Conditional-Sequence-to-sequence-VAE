{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __save_model(model_name, model, root):\n",
    "    if not os.path.isdir(root):\n",
    "        os.mkdir(root)\n",
    "    p = os.path.join(root, '{}-params.pkl'.format(model_name))\n",
    "    torch.save(model.state_dict(), p)\n",
    "    return p\n",
    "\n",
    "def save_model(models, root='./model'):\n",
    "    p = {}\n",
    "    for k, m in models.items():\n",
    "        p[k] = __save_model(k, m, root)\n",
    "    return p\n",
    "\n",
    "def __load_model(model_name, model, root):\n",
    "    p = os.path.join(root, '{}-params.pkl'.format(model_name))\n",
    "    if not os.path.isfile(p):\n",
    "        msg = \"No model parameters file for {}!\".format(model_name)\n",
    "        return print(msg)\n",
    "        raise AttributeError(msg)\n",
    "    paras = torch.load(p)\n",
    "    model.load_state_dict(paras)\n",
    "\n",
    "def load_model(models, root='./model'):\n",
    "    for k, m in models.items():\n",
    "        __load_model(k, m, root)\n",
    "        \n",
    "def save_model_by_score(models, bleu_score, root):\n",
    "    p = os.path.join(root, 'score.json')\n",
    "    previous = None\n",
    "    \n",
    "    if np.isnan(bleu_score):\n",
    "        raise AttributeError(\"BLEU score become {}\".format(bleu_score))\n",
    "        return\n",
    "    \n",
    "    if os.path.isfile(p):\n",
    "        with open(p, 'r') as f:\n",
    "            previous = json.load(f)\n",
    "            \n",
    "    if previous is not None and previous['score'] > bleu_score:\n",
    "        return;\n",
    "    \n",
    "    save_model(models, root)\n",
    "    previous = {'score' : bleu_score}\n",
    "    with open(p, 'w') as f:\n",
    "        json.dump(previous, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDict:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0\n",
    "        \n",
    "        for i in range(26):\n",
    "            self.addWord(chr(ord('a') + i))\n",
    "        \n",
    "        tokens = [\"SOS\", \"EOS\"]\n",
    "        for t in tokens:\n",
    "            self.addWord(t)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "\n",
    "    def longtensorFromString(self, s):\n",
    "        s = [\"SOS\"] + list(s) + [\"EOS\"]\n",
    "        return torch.LongTensor([self.word2index[ch] for ch in s])\n",
    "    \n",
    "    def stringFromLongtensor(self, l, show_token=False, check_end=True):\n",
    "        s = \"\"\n",
    "        for i in l:\n",
    "            ch = self.index2word[i.item()]\n",
    "            if len(ch) > 1:\n",
    "                if show_token:\n",
    "                    __ch = \"<{}>\".format(ch)\n",
    "                else:\n",
    "                    __ch = \"\"\n",
    "            else:\n",
    "                __ch = ch\n",
    "            s += __ch\n",
    "            if check_end and ch == \"EOS\":\n",
    "                break\n",
    "        return s\n",
    "\n",
    "class wordsDataset(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            f = './train.txt'\n",
    "        else:\n",
    "            f = './test.txt'\n",
    "        self.datas = np.loadtxt(f, dtype=np.str)\n",
    "        \n",
    "        if train:\n",
    "            self.datas = self.datas.reshape(-1)\n",
    "        else:\n",
    "            '''\n",
    "            sp -> p\n",
    "            sp -> pg\n",
    "            sp -> tp\n",
    "            sp -> tp\n",
    "            p  -> tp\n",
    "            sp -> pg\n",
    "            p  -> sp\n",
    "            pg -> sp\n",
    "            pg -> p\n",
    "            pg -> tp\n",
    "            '''\n",
    "            self.targets = np.array([\n",
    "                [0, 3],\n",
    "                [0, 2],\n",
    "                [0, 1],\n",
    "                [0, 1],\n",
    "                [3, 1],\n",
    "                [0, 2],\n",
    "                [3, 0],\n",
    "                [2, 0],\n",
    "                [2, 3],\n",
    "                [2, 1],\n",
    "            ])\n",
    "        \n",
    "        #self.tenses = ['sp', 'tp', 'pg', 'p']\n",
    "        self.tenses = [\n",
    "            'simple-present', \n",
    "            'third-person', \n",
    "            'present-progressive', \n",
    "            'simple-past'\n",
    "        ]\n",
    "        self.chardict = CharDict()\n",
    "        \n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            c = index % len(self.tenses)\n",
    "            return self.chardict.longtensorFromString(self.datas[index]), c\n",
    "        else:\n",
    "            i = self.chardict.longtensorFromString(self.datas[index, 0])\n",
    "            ci = self.targets[index, 0]\n",
    "            o = self.chardict.longtensorFromString(self.datas[index, 1])\n",
    "            co = self.targets[index, 1]\n",
    "            \n",
    "            return i, ci, o, co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, word_size, hidden_size, latent_size, \n",
    "        num_condition, condition_size\n",
    "    ):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.word_size = word_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.condition_size = condition_size\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.condition_embedding = nn.Embedding(num_condition, condition_size)\n",
    "        self.word_embedding = nn.Embedding(word_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.mean = nn.Linear(hidden_size, latent_size)\n",
    "        self.logvar = nn.Linear(hidden_size, latent_size)\n",
    "\n",
    "    def forward(self, inputs, init_hidden, input_condition):\n",
    "        c = self.condition(input_condition)\n",
    "        \n",
    "        # get (1,1,hidden_size)\n",
    "        hidden = torch.cat((init_hidden, c), dim=2)\n",
    "        \n",
    "        # get (seq, 1, hidden_size)\n",
    "        x = self.word_embedding(inputs).view(-1, 1, self.hidden_size)\n",
    "        \n",
    "        # get (seq, 1, hidden_size), (1, 1, hidden_size)\n",
    "        outputs, hidden = self.gru(x, hidden)\n",
    "        \n",
    "        # get (1, 1, hidden_size)\n",
    "        m = self.mean(hidden)\n",
    "        logvar = self.logvar(hidden)\n",
    "        \n",
    "        z = self.sample_z() * torch.exp(logvar/2) + m\n",
    "        \n",
    "        #self.m = m\n",
    "        #self.logvar = logvar\n",
    "        \n",
    "        return z, m, logvar\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(\n",
    "            1, 1, self.hidden_size - self.condition_size, \n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    def condition(self, c):\n",
    "        c = torch.LongTensor([c]).to(device)\n",
    "        return self.condition_embedding(c).view(1,1,-1)\n",
    "    \n",
    "    def sample_z(self):\n",
    "        return torch.normal(\n",
    "            torch.FloatTensor([0]*self.latent_size), \n",
    "            torch.FloatTensor([1]*self.latent_size)\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, word_size, hidden_size, latent_size, condition_size\n",
    "    ):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.word_size = word_size\n",
    "\n",
    "        self.latent_to_hidden = nn.Linear(\n",
    "            latent_size+condition_size, hidden_size\n",
    "        )\n",
    "        self.word_embedding = nn.Embedding(word_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, word_size)\n",
    "        \n",
    "    def forward(self, inputs, z, c, teacher=False, hidden=None):\n",
    "        # get (1,1,latent_size + condition_size)\n",
    "        latent = torch.cat((z, c), dim=2)\n",
    "        \n",
    "        # get (1,1,hidden_size)\n",
    "        if hidden is None:\n",
    "            hidden = self.latent_to_hidden(latent)\n",
    "            #print(\"get hidden from latent\")\n",
    "        \n",
    "        # get (seq, 1, hidden_size)\n",
    "        x = self.word_embedding(inputs).view(-1, 1, self.hidden_size)\n",
    "        \n",
    "        input_length = x.size(0)\n",
    "        \n",
    "        # get (seq, 1, hidden_size), (1, 1, hidden_size)\n",
    "        if teacher:\n",
    "            outputs = []\n",
    "            for i in range(input_length-1):\n",
    "                output, hidden = self.gru(x[i:i+1], hidden)\n",
    "                hidden = x[i+1:i+2]\n",
    "                outputs.append(output)\n",
    "            \n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "        else:\n",
    "            # Omit EOS token\n",
    "            x = x[:-1]\n",
    "            outputs, hidden = self.gru(x, hidden)\n",
    "            \n",
    "        # get (seq, word_size)\n",
    "        outputs = self.out(outputs).view(-1, self.word_size)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "train_dataset = wordsDataset()\n",
    "test_dataset = wordsDataset(False)\n",
    "\n",
    "word_size = train_dataset.chardict.n_words\n",
    "num_condition = len(train_dataset.tenses)\n",
    "hidden_size = 256\n",
    "latent_size = 32\n",
    "condition_size = 8\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "empty_input_ratio = 0.1\n",
    "KLD_weight = 0.0\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(EncoderRNN(\n",
       "   (condition_embedding): Embedding(4, 8)\n",
       "   (word_embedding): Embedding(28, 256)\n",
       "   (gru): GRU(256, 256)\n",
       "   (mean): Linear(in_features=256, out_features=32, bias=True)\n",
       "   (logvar): Linear(in_features=256, out_features=32, bias=True)\n",
       " ), DecoderRNN(\n",
       "   (latent_to_hidden): Linear(in_features=40, out_features=256, bias=True)\n",
       "   (word_embedding): Embedding(28, 256)\n",
       "   (gru): GRU(256, 256)\n",
       "   (out): Linear(in_features=256, out_features=28, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = EncoderRNN(\n",
    "    word_size, hidden_size, latent_size, num_condition, condition_size\n",
    ").to(device)\n",
    "decoder = DecoderRNN(\n",
    "    word_size, hidden_size, latent_size, condition_size\n",
    ").to(device)\n",
    "encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(\n",
    "    {'encoder':encoder, 'decoder':decoder}, \n",
    "    os.path.join('.', 'best')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL weights\n",
    "## loss = cross_entropy + (kl w)*KL($q(Z|X, c;\\theta') || p(Z|c)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    return sentence_bleu(\n",
    "        [reference], output,\n",
    "        weights=(0.25, 0.25, 0.25, 0.25),smoothing_function=cc.method1\n",
    "    )\n",
    "\n",
    "def evaluation(encoder, decoder, dataset,show=True):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    char_accuracy_total = 0\n",
    "    char_accuracy_len = 0\n",
    "    \n",
    "    blue_score = []\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        data = dataset[idx]\n",
    "        if dataset.train:\n",
    "            inputs, input_condition = data\n",
    "            targets = inputs\n",
    "            target_condition = input_condition\n",
    "        else:\n",
    "            inputs, input_condition, targets, target_condition = data\n",
    "            \n",
    "        # input no sos and eos\n",
    "        z, _, _ = encoder(inputs[1:-1].to(device), encoder.initHidden(), input_condition)\n",
    "            \n",
    "        # input has sos\n",
    "        outputs, _ = decoder(targets.to(device), z, encoder.condition(target_condition), False)\n",
    "            \n",
    "        # show output by string\n",
    "        outputs_onehot = torch.max(torch.softmax(outputs, dim=1), 1)[1]\n",
    "        inputs_str = train_dataset.chardict.stringFromLongtensor(inputs, check_end=True)\n",
    "        targets_str = train_dataset.chardict.stringFromLongtensor(targets, check_end=True)\n",
    "        outputs_str = train_dataset.chardict.stringFromLongtensor(outputs_onehot, check_end=True)\n",
    "        \n",
    "        if show:\n",
    "            print(inputs_str, '->', targets_str,':',outputs_str)\n",
    "            \n",
    "        char_accuracy_total += (outputs_onehot[:-1] == targets[1:-1].to(device)).sum().item()\n",
    "        char_accuracy_len += len(targets[1:-1])\n",
    "        \n",
    "        blue_score.append( compute_bleu(outputs_str, targets_str) )\n",
    "    \n",
    "    if show:\n",
    "        print('Accuracy per char : {}'.format(char_accuracy_total / char_accuracy_len))\n",
    "        print('BLEU-4 score : {}'.format(sum(blue_score) / len(blue_score)))\n",
    "    \n",
    "    return blue_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLD_weight_annealing(*args):\n",
    "    epoch, batch = args\n",
    "    slope = 0.001\n",
    "    #slope = 0.1\n",
    "    scope = (1.0 / slope)*2\n",
    "    \n",
    "    w = (epoch % scope) * slope\n",
    "    \n",
    "    if w > 1.0:\n",
    "        w = 1.0\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '{:4d}m {:2d}s'.format(int(m), int(s))\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def KL_loss(m, logvar):\n",
    "    return torch.sum(0.5 * (-logvar + (m**2) + torch.exp(logvar) - 1))\n",
    "\n",
    "def trainEpochs(\n",
    "    name, encoder, decoder, epoch_size, learning_rate=1e-2,\n",
    "    show_size=1000, KLD_weight=0.0, teacher_forcing_ratio = 1.0, eval_size=100\n",
    "):  \n",
    "    start = time.time()\n",
    "    plots = []\n",
    "    show_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    plot_kl_loss_total = 0\n",
    "    char_accuracy_total = 0\n",
    "    char_accuracy_len = 0\n",
    "    \n",
    "    kld_w = 0.0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    for epoch in range(epoch_size):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        # get data from trian dataset\n",
    "        for idx in range(len(train_dataset)):   \n",
    "        #for idx in range(1):\n",
    "            data = train_dataset[idx]\n",
    "            inputs, c = data\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "            # input no sos and eos\n",
    "            z, m, logvar = encoder(inputs[1:-1].to(device), encoder.initHidden(), c)\n",
    "            \n",
    "            # decide teacher forcing\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            \n",
    "            # input has sos\n",
    "            outputs, _ = decoder(inputs.to(device), z, encoder.condition(c), use_teacher_forcing)\n",
    "            \n",
    "            # target no sos\n",
    "            loss = criterion(outputs, inputs[1:].to(device))\n",
    "            kld_loss = KL_loss(m, logvar)\n",
    "            #loss = criterion(outputs, inputs[:-1].to(device))\n",
    "            if callable(KLD_weight):\n",
    "                kld_w = KLD_weight(epoch, idx)\n",
    "            else:\n",
    "                kld_w = KLD_weight\n",
    "                \n",
    "            #print('crossentropy : {} , kld : {}'.format(loss.item(), kld_loss.item()))\n",
    "                \n",
    "            (loss + (kld_w * kld_loss)).backward()\n",
    "            \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "            show_loss_total += loss.item() + ( kld_w*kld_loss.item() )\n",
    "            plot_loss_total += loss.item()\n",
    "            plot_kl_loss_total += kld_loss.item()\n",
    "            \n",
    "            # show output by string\n",
    "            # outputs_onehot = torch.max(outputs, 1)[1]\n",
    "            outputs_onehot = torch.max(torch.softmax(outputs, dim=1), 1)[1]\n",
    "            inputs_str = train_dataset.chardict.stringFromLongtensor(inputs, show_token=True)\n",
    "            outputs_str = train_dataset.chardict.stringFromLongtensor(outputs_onehot, show_token=True)\n",
    "            #print(inputs_str,':',outputs_str)\n",
    "            \n",
    "            char_accuracy_total += (outputs_onehot[:-1] == inputs[1:-1].to(device)).sum().item()\n",
    "            char_accuracy_len += len(inputs[1:-1])\n",
    "            \n",
    "        score = 0\n",
    "        for _ in range(eval_size):\n",
    "            all_score = evaluation(encoder, decoder, test_dataset, show=False)\n",
    "            score += sum(all_score) / len(all_score)\n",
    "        score /= eval_size\n",
    "        \n",
    "        save_model_by_score(\n",
    "            {'encoder':encoder, 'decoder':decoder}, \n",
    "            score, \n",
    "            os.path.join('.', name)\n",
    "        )\n",
    "        \n",
    "        if (epoch + 1)%show_size == 0:\n",
    "            show_loss_total /= show_size\n",
    "            print(\"{} ({} {}%) \\ntotal loss : {:.4f}\".format(\n",
    "                timeSince(start, (epoch+1) / epoch_size),\n",
    "                epoch+1, (epoch+1)*100/epoch_size, show_loss_total\n",
    "            ))\n",
    "            print('bleu score : {:.5f}\\n'.format(score))\n",
    "            show_loss_total = 0\n",
    "        \n",
    "        plots.append((plot_loss_total, plot_kl_loss_total, kld_w, score))\n",
    "        \n",
    "        plot_loss_total = 0\n",
    "        plot_kl_loss_total = 0\n",
    "        char_accuracy_total = 0\n",
    "        char_accuracy_len = 0\n",
    "        \n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-2a620421d75b>\u001b[0m in \u001b[0;36mtrainEpochs\u001b[0;34m(name, encoder, decoder, epoch_size, learning_rate, show_size, KLD_weight, teacher_forcing_ratio, eval_size)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#print(inputs_str,':',outputs_str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mchar_accuracy_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mchar_accuracy_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics = trainEpochs(\n",
    "    'training', \n",
    "    encoder, decoder, \n",
    "    epoch_size=2000, show_size=50, \n",
    "    KLD_weight=KLD_weight_annealing, teacher_forcing_ratio=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder': './best/encoder-params.pkl',\n",
       " 'decoder': './best/decoder-params.pkl'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model({'encoder':encoder, 'decoder':decoder}, \n",
    "    os.path.join('.', 'best'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandon -> abandoned : abodooned\n",
      "abet -> abetting : abatiing\n",
      "begin -> begins : begina\n",
      "expend -> expends : pxpunds\n",
      "sent -> sends : stnti\n",
      "split -> splitting : splitcing\n",
      "flared -> flare : frare\n",
      "functioning -> function : function\n",
      "functioning -> functioned : fucctioned\n",
      "healing -> heals : leals\n",
      "Accuracy per char : 0.7916666666666666\n",
      "BLEU-4 score : 0.4872308083596142\n"
     ]
    }
   ],
   "source": [
    "all_score = evaluation(encoder, decoder, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word(encoder, decoder, z, condition, maxlen=20):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    z = z.view(1,1,-1)\n",
    "    sos_token = train_dataset.chardict.word2index['SOS']\n",
    "    eos_token = train_dataset.chardict.word2index['EOS']\n",
    "    inputs = torch.LongTensor([sos_token, eos_token])\n",
    "    outputs = []\n",
    "    i = 0\n",
    "    hidden = None\n",
    "    \n",
    "    while True:\n",
    "        # get (1, word_size)\n",
    "        output, hidden = decoder(\n",
    "            inputs.to(device), \n",
    "            z.to(device), \n",
    "            encoder.condition(condition),\n",
    "            False,\n",
    "            hidden\n",
    "        )\n",
    "        output_onehot = torch.max(torch.softmax(output, dim=1), 1)[1]\n",
    "        if output_onehot.item() == eos_token:\n",
    "            break\n",
    "        \n",
    "        outputs.append(output_onehot.item())\n",
    "        i += 1\n",
    "        if maxlen <= i:\n",
    "            break\n",
    "        \n",
    "        inputs = torch.LongTensor([outputs[-1], eos_token])\n",
    "        \n",
    "    return torch.LongTensor(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = encoder.sample_z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0209, -0.5143, -0.3733, -0.5860, -0.2405,  0.4617, -0.3758, -0.8812,\n",
      "         0.0183, -0.4252, -0.3789,  0.3323,  1.1544,  1.1311,  0.5999,  0.7094,\n",
      "         0.9903,  1.0437, -1.4360,  1.6086,  0.0339, -0.2418,  0.2178, -1.4280,\n",
      "         0.4243,  2.7477,  0.5215,  0.1661,  1.0378,  2.2851,  0.7405, -1.5749],\n",
      "       device='cuda:0')\n",
      "simple-present       : absing\n",
      "third-person         : dinquists\n",
      "present-progressive  : absing\n",
      "simple-past          : absing\n"
     ]
    }
   ],
   "source": [
    "print(noise)\n",
    "for i in range(len(train_dataset.tenses)):\n",
    "    outputs = generate_word(encoder, decoder, noise, i)\n",
    "    output_str = train_dataset.chardict.stringFromLongtensor(outputs)\n",
    "    print('{:20s} : {}'.format(train_dataset.tenses[i],output_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0209, -0.5143, -0.3733, -0.5860, -0.2405,  0.4617, -0.3758, -0.8812,\n",
      "         0.0183, -0.4252, -0.3789,  0.3323,  1.1544,  1.1311,  0.5999,  0.7094,\n",
      "         0.9903,  1.0437, -1.4360,  1.6086,  0.0339, -0.2418,  0.2178, -1.4280,\n",
      "         0.4243,  2.7477,  0.5215,  0.1661,  1.0378,  2.2851,  0.7405, -1.5749],\n",
      "       device='cuda:0')\n",
      "simple-present       : absing\n",
      "third-person         : dinquists\n",
      "present-progressive  : absing\n",
      "simple-past          : absing\n"
     ]
    }
   ],
   "source": [
    "print(noise)\n",
    "for i in range(len(train_dataset.tenses)):\n",
    "    outputs = generate_word(encoder, decoder, noise, i)\n",
    "    output_str = train_dataset.chardict.stringFromLongtensor(outputs)\n",
    "    print('{:20s} : {}'.format(train_dataset.tenses[i],output_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0209, -0.5143, -0.3733, -0.5860, -0.2405,  0.4617, -0.3758, -0.8812,\n",
      "         0.0183, -0.4252, -0.3789,  0.3323,  1.1544,  1.1311,  0.5999,  0.7094,\n",
      "         0.9903,  1.0437, -1.4360,  1.6086,  0.0339, -0.2418,  0.2178, -1.4280,\n",
      "         0.4243,  2.7477,  0.5215,  0.1661,  1.0378,  2.2851,  0.7405, -1.5749],\n",
      "       device='cuda:0')\n",
      "simple-present       : absing\n",
      "third-person         : dinquists\n",
      "present-progressive  : absing\n",
      "simple-past          : absing\n"
     ]
    }
   ],
   "source": [
    "print(noise)\n",
    "for i in range(len(train_dataset.tenses)):\n",
    "    outputs = generate_word(encoder, decoder, noise, i)\n",
    "    output_str = train_dataset.chardict.stringFromLongtensor(outputs)\n",
    "    print('{:20s} : {}'.format(train_dataset.tenses[i],output_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
